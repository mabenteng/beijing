{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time,re,json\n",
    "headers= {\n",
    "    # 'Host': 'weixin.sogou.com',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Accept': 'text/html, */*; q=0.01',\n",
    "    # 'X-Requested-With': 'XMLHttpRequest',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36',\n",
    "    # 'Referer': 'https://weixin.sogou.com/weixin?query=%E5%86%9B%E6%B0%91%E8%9E%8D%E5%90%88&_sug_type_=&s_from=input&_sug_=n&type=2&page=5&ie=utf8',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "    # 'Set-Cookie':'SNUID=1; domain=.sogou.com; path=/; expires=Thu, 01-Dec-1994 16:00:00 GMT'\n",
    "    # 'cookie':'UM_distinctid=17849b7fde95a7-03eff9e74a246a-5771031-1fa400-17849b7fdea6e7; aliyungf_tc=0ad34eaa0bc833366341a163101e37f326a55e86b84bd6819ac56c2487e694ad; route=030e64943c5930d7318fe4a07bfd2a3c; JSESSIONID=C27824A0F7F089A9CA374ACB3A823D18; uuid=e52f2562-34cd-478a-a25e-d475921f180b; SERVERID=srv-omp-ali-portal11_80; Hm_lvt_94a1e06bbce219d29285cee2e37d1d26=1616144498,1616658796,1616721884; paperSearhType=1; CNZZDATA1261102524=591838861-1616142188-%7C1616750557; Hm_lpvt_94a1e06bbce219d29285cee2e37d1d26=1616755493'\n",
    "}\n",
    "url=\"https://jobs.51job.com/all/115616698.html?s=01&t=7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "info=requests.get(url,headers=headers)\n",
    "info.encoding=info.apparent_encoding\n",
    "soup=bs(info.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 列表详情 包含地点,要求,学历,人数,时间\\nlistinfo=soup.find_all(\"div\",class_=\"cn\")[0].select(\"p.msg.ltype\")[0].get_text(strip=True).split(\"|\")\\n# 工作地点\\nlistinfo[0]\\n# 工作经验要求\\nlistinfo[1]\\n# 学历要求\\nlistinfo[2]\\n# 招聘人数\\nlistinfo[3]\\n# 发布时间=========05-11发布\\nlistinfo[4]\\n# 所属部门\\nsoup.find_all(class_=\"tCompany_main\")[0].select(\"div.tBorderTop_box div.bmsg.inbox\")[1].find(\"span\").next_sibling\\n# 职位详细信息\\n# 先删除职位下的div无用元素\\nxx=soup.find_all(class_=\"tCompany_main\")[0].select(\"div.tBorderTop_box div.bmsg.inbox\")[0].find_all(\"div\",recursive=False)\\n[x.extract() for x in xx]\\nsoup.find_all(class_=\"tCompany_main\")[0].select(\"div.tBorderTop_box div.bmsg.inbox\")[0].decode_contents()\\n# print(jobinfo[0])\\n'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=bs(info.text,\"html.parser\")\n",
    "# 岗位名称\n",
    "soup.find_all(class_=\"cn\")[0].find(\"h1\").contents[0]\n",
    "# 招聘部门\n",
    "soup.find_all(class_=\"cn\")[0].select(\"p.cname a.catn\")[0].get_text()\n",
    "''''''\n",
    "# 列表详情 包含地点,要求,学历,人数,时间\n",
    "listinfo=soup.find_all(\"div\",class_=\"cn\")[0].select(\"p.msg.ltype\")[0].get_text(strip=True).split(\"|\")\n",
    "# 工作地点\n",
    "listinfo[0]\n",
    "# 工作经验要求\n",
    "listinfo[1]\n",
    "# 学历要求\n",
    "listinfo[2]\n",
    "# 招聘人数\n",
    "listinfo[3]\n",
    "# 发布时间=========05-11发布\n",
    "listinfo[4]\n",
    "# 所属部门\n",
    "soup.find_all(class_=\"tCompany_main\")[0].select(\"div.tBorderTop_box div.bmsg.inbox\")[1].find(\"span\").next_sibling\n",
    "# 职位详细信息\n",
    "# 先删除职位下的div无用元素\n",
    "xx=soup.find_all(class_=\"tCompany_main\")[0].select(\"div.tBorderTop_box div.bmsg.inbox\")[0].find_all(\"div\",recursive=False)\n",
    "[x.extract() for x in xx]\n",
    "soup.find_all(class_=\"tCompany_main\")[0].select(\"div.tBorderTop_box div.bmsg.inbox\")[0].decode_contents()\n",
    "# print(jobinfo[0])\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clear']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"div\",class_=\"t1\").select_one(\"div.clear\").get(\"class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'投资银行总部'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"tCompany_main\")[0].select(\"div.tBorderTop_box div.bmsg.inbox\")[1].find(\"span\").next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 列表页ajax生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://companyads.51job.com/companyads/2020/sh/htzq/job.html\"\n",
    "res=requests.get(url,headers=headers,timeout=8)\n",
    "res.encoding=res.apparent_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-94698841c5c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lll\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lll'"
     ]
    }
   ],
   "source": [
    "# 导入collections官方模块使用defaultdict方法来解决访问不存在键报错的问题\n",
    "\n",
    "import collections\n",
    "\n",
    "dc=collections.defaultdict(None)\n",
    "\n",
    "dc[\"kk\"]=\"88888888888\"\n",
    "dc\n",
    "\n",
    "print(bool(dc[\"lll\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9==8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n工作职责：\\n\\n   -\\t包括但不限于开发A股股票市场选股因子，深入研究多因子模型体系和优化风险模型等；\\n-\\t开发统计套利，股票日内交易等及其它量化投资策略；\\n-\\t协助数据维护与数据可视化工作；\\n-\\t协助维护日常交易系统及数据；\\n-\\t其他相关工作。\\n\\n\\n任职资格：\\n\\n   -\\t富有团队合作精神，具备良好的沟通能力和解决问题的能力；\\n-\\t拥有较强阅读学术文献并复现的能力，具备较强的学术功底；至少对以下一个领域有深入的学习和研究：\\n\\uf09f\\t机器学习\\n\\uf09f\\t计量经济学\\n\\uf09f\\t宏观经济学\\n-\\t具备基本的金融市场知识，具有量化投资实习经验者优先考虑；\\n-\\t精通Python, R或C++/C中至少一门编程语言，具备优秀的编程能力及良好的编程习惯；\\n-\\t熟练掌握Linux，熟练掌握sql语言与vba编程；\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "aa=\"\"\"<div >\n",
    "   <h2>工作职责：</h2>\n",
    "   -\t包括但不限于开发A股股票市场选股因子，深入研究多因子模型体系和优化风险模型等；<br>-\t开发统计套利，股票日内交易等及其它量化投资策略；<br>-\t协助数据维护与数据可视化工作；<br>-\t协助维护日常交易系统及数据；<br>-\t其他相关工作。<br><br>\n",
    "   <h2>任职资格：</h2>\n",
    "   -\t富有团队合作精神，具备良好的沟通能力和解决问题的能力；<br>-\t拥有较强阅读学术文献并复现的能力，具备较强的学术功底；至少对以下一个领域有深入的学习和研究：<br>\t机器学习<br>\t计量经济学<br>\t宏观经济学<br>-\t具备基本的金融市场知识，具有量化投资实习经验者优先考虑；<br>-\t精通Python, R或C++/C中至少一门编程语言，具备优秀的编程能力及良好的编程习惯；<br>-\t熟练掌握Linux，熟练掌握sql语言与vba编程；<br><br>\n",
    "  </div>\n",
    "\"\"\"\n",
    "soup=bs(aa,\"html.parser\")\n",
    "\n",
    "soup.get_text(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy,pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
